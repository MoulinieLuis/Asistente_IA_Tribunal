# üìö Asistente Inteligente de Consulta Jur√≠dica

## üìå Descripci√≥n General
Este proyecto es un **asistente de consultas jur√≠dicas** que combina:
1. **Un motor sem√°ntico** que busca informaci√≥n relevante en manuales oficiales del tribunal.
2. **Un modelo de IA** que genera respuestas completas y coherentes basadas en la informaci√≥n encontrada y en la pregunta del usuario.

El objetivo es proporcionar respuestas precisas y fundamentadas, integrando **conocimiento humano (manuales)** con **capacidad generativa de IA**.

---

## ‚öôÔ∏è Funcionamiento General

1. **Recepci√≥n de la pregunta**
   - Un usuario env√≠a su consulta a la API del proyecto.

2. **B√∫squeda sem√°ntica**
   - El motor sem√°ntico analiza la pregunta y encuentra fragmentos relevantes en los manuales del tribunal.
   - Se utiliza **FAISS** como √≠ndice vectorial para buscar por similitud de significado.

3. **Generaci√≥n de respuesta**
   - El contexto relevante (texto de manuales) y la pregunta se env√≠an al **modelo de IA local**.
   - La IA combina la informaci√≥n encontrada con su propio conocimiento para generar una respuesta clara.

4. **Devoluci√≥n al usuario**
   - La respuesta final se env√≠a en formato JSON.

---

## üß© Componentes del Proyecto

- **`main.py`**  
  Contiene la API desarrollada en **FastAPI**.  
  Expone los endpoints para recibir consultas y devolver respuestas.

- **`semantic_engine.py`**  
  M√≥dulo que maneja la b√∫squeda sem√°ntica usando FAISS y embeddings.

- **`ia_connector.py`**  
  M√≥dulo que gestiona la conexi√≥n con el modelo de IA local.

- **`requirements.txt`**  
  Lista de dependencias necesarias para instalar el entorno.

- **`data/manuals`** *(opcional)*  
  Carpeta donde se almacenan los manuales del tribunal en texto plano para ser indexados.

---

## üîó Flujo de Relaci√≥n entre Componentes

## üñ•Ô∏è Requerimientos del Sistema

- **Python** 3.9 o superior  
- **FastAPI** y **Uvicorn** para la API  
- **FAISS** para b√∫squeda sem√°ntica  
- **SentenceTransformers** para embeddings  
- **Transformers** y modelo local compatible  
- Sistema operativo: Linux, macOS o Windows  
- Al menos **8 GB de RAM** (recomendado 16 GB si el modelo es grande)  
- GPU con soporte CUDA *(opcional pero recomendado)*

---

## üì¶ Instalaci√≥n

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/usuario/asistente-juridico.git
   cd asistente-juridico

2. **Crear entorno virtual**
  python -m venv venv
  source venv/bin/activate   # En Windows: venv\Scripts\activate

3. **Instalar dependencias**
  pip install -r requirements.txt


4. **Indexar manuales (opcional si ya existe el √≠ndice)**
  python semantic_engine.py --index


## üöÄ Ejecuci√≥n

1. **Iniciar la API con recarga autom√°tica:**
  uvicorn main:app --reload


**La API de IA existe cuando se descaga la aplicaci√≥n Ollama y se instala la IA "Mistral"**
  Puerto (localhost): http://127.0.0.1:8000


## üìã Ejemplo de Uso

**Solicitud:**

curl -X POST "http://127.0.0.1:8000/query" \
     -H "Content-Type: application/json" \
     -d '{"question": "¬øCu√°l es el procedimiento para apelar una sentencia?"}'


**Respuesta:**

{
  "answer": "Seg√∫n el manual del tribunal, el procedimiento para apelar...",
  "source": "Manual de Procedimientos, Cap√≠tulo 4"
}


## üë• Colaboraci√≥n

**Para contribuir:**

Crear una nueva rama.

Realizar cambios y pruebas.

Hacer un Pull Request con una descripci√≥n clara de las modificaciones.

![Arquitectura del Proyecto](img/arquitectura_proyecto_asistente.png)
